{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5957883b-64c2-4f6a-a0a1-cb293dad8930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client_Income</th>\n",
       "      <th>Credit_Amount</th>\n",
       "      <th>Loan_Annuity</th>\n",
       "      <th>Age_Days</th>\n",
       "      <th>Employed_Days</th>\n",
       "      <th>Registration_Days</th>\n",
       "      <th>ID_Days</th>\n",
       "      <th>Phone_Change</th>\n",
       "      <th>Credit_Bureau</th>\n",
       "      <th>Divorce</th>\n",
       "      <th>Education_Days</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33750</td>\n",
       "      <td>133988</td>\n",
       "      <td>3547</td>\n",
       "      <td>7716</td>\n",
       "      <td>2977</td>\n",
       "      <td>5516</td>\n",
       "      <td>4043</td>\n",
       "      <td>674</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4380</td>\n",
       "      <td>2023-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11250</td>\n",
       "      <td>13752</td>\n",
       "      <td>653</td>\n",
       "      <td>10231</td>\n",
       "      <td>1184</td>\n",
       "      <td>3910</td>\n",
       "      <td>3910</td>\n",
       "      <td>739</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4380</td>\n",
       "      <td>2023-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15750</td>\n",
       "      <td>128835</td>\n",
       "      <td>3779</td>\n",
       "      <td>17673</td>\n",
       "      <td>365243</td>\n",
       "      <td>113</td>\n",
       "      <td>4855</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4380</td>\n",
       "      <td>2023-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13500</td>\n",
       "      <td>60415</td>\n",
       "      <td>3097</td>\n",
       "      <td>18843</td>\n",
       "      <td>365243</td>\n",
       "      <td>12617</td>\n",
       "      <td>5280</td>\n",
       "      <td>1687</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4380</td>\n",
       "      <td>2023-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12150</td>\n",
       "      <td>16320</td>\n",
       "      <td>1294</td>\n",
       "      <td>16857</td>\n",
       "      <td>365243</td>\n",
       "      <td>2834</td>\n",
       "      <td>4053</td>\n",
       "      <td>533</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4380</td>\n",
       "      <td>2023-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106985</th>\n",
       "      <td>7650</td>\n",
       "      <td>33294</td>\n",
       "      <td>1479</td>\n",
       "      <td>18203</td>\n",
       "      <td>365243</td>\n",
       "      <td>10227</td>\n",
       "      <td>5155</td>\n",
       "      <td>1707</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4380</td>\n",
       "      <td>2024-12-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106986</th>\n",
       "      <td>11250</td>\n",
       "      <td>155881</td>\n",
       "      <td>5611</td>\n",
       "      <td>19886</td>\n",
       "      <td>365243</td>\n",
       "      <td>12953</td>\n",
       "      <td>5243</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4380</td>\n",
       "      <td>2024-12-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106987</th>\n",
       "      <td>9450</td>\n",
       "      <td>27252</td>\n",
       "      <td>1754</td>\n",
       "      <td>20652</td>\n",
       "      <td>365243</td>\n",
       "      <td>4154</td>\n",
       "      <td>4155</td>\n",
       "      <td>1647</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4380</td>\n",
       "      <td>2024-12-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106988</th>\n",
       "      <td>54000</td>\n",
       "      <td>52128</td>\n",
       "      <td>2742</td>\n",
       "      <td>9954</td>\n",
       "      <td>796</td>\n",
       "      <td>4394</td>\n",
       "      <td>722</td>\n",
       "      <td>426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4380</td>\n",
       "      <td>2024-12-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106989</th>\n",
       "      <td>13500</td>\n",
       "      <td>25470</td>\n",
       "      <td>1435</td>\n",
       "      <td>17814</td>\n",
       "      <td>2335</td>\n",
       "      <td>7722</td>\n",
       "      <td>2637</td>\n",
       "      <td>1186</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5840</td>\n",
       "      <td>2024-12-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106990 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Client_Income  Credit_Amount  Loan_Annuity  Age_Days  Employed_Days  \\\n",
       "0               33750         133988          3547      7716           2977   \n",
       "1               11250          13752           653     10231           1184   \n",
       "2               15750         128835          3779     17673         365243   \n",
       "3               13500          60415          3097     18843         365243   \n",
       "4               12150          16320          1294     16857         365243   \n",
       "...               ...            ...           ...       ...            ...   \n",
       "106985           7650          33294          1479     18203         365243   \n",
       "106986          11250         155881          5611     19886         365243   \n",
       "106987           9450          27252          1754     20652         365243   \n",
       "106988          54000          52128          2742      9954            796   \n",
       "106989          13500          25470          1435     17814           2335   \n",
       "\n",
       "        Registration_Days  ID_Days  Phone_Change  Credit_Bureau  Divorce  \\\n",
       "0                    5516     4043           674              1        0   \n",
       "1                    3910     3910           739              0        0   \n",
       "2                     113     4855             0              3        0   \n",
       "3                   12617     5280          1687              4        0   \n",
       "4                    2834     4053           533              5        0   \n",
       "...                   ...      ...           ...            ...      ...   \n",
       "106985              10227     5155          1707              1        0   \n",
       "106986              12953     5243          2018              4        0   \n",
       "106987               4154     4155          1647              1        0   \n",
       "106988               4394      722           426              0        0   \n",
       "106989               7722     2637          1186              2        0   \n",
       "\n",
       "        Education_Days       Date  \n",
       "0                 4380 2023-05-01  \n",
       "1                 4380 2023-05-01  \n",
       "2                 4380 2023-05-01  \n",
       "3                 4380 2023-05-01  \n",
       "4                 4380 2023-05-01  \n",
       "...                ...        ...  \n",
       "106985            4380 2024-12-18  \n",
       "106986            4380 2024-12-18  \n",
       "106987            4380 2024-12-18  \n",
       "106988            4380 2024-12-18  \n",
       "106989            5840 2024-12-18  \n",
       "\n",
       "[106990 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' This script prepares raw data for model training and mock year data generation '''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_1 = pd.read_csv(\"Train_Dataset.csv\", low_memory=False)\n",
    "df_2 = pd.read_csv(\"Test_Dataset.csv\", low_memory=False)\n",
    "df_3 = pd.read_csv(\"Sample_Submission.csv\", low_memory=False)\n",
    "merged_df = pd.merge(\n",
    "    df_2,          # First DataFrame\n",
    "    df_3,          # Second DataFrame\n",
    "    on='ID',       # Common column\n",
    "    how='inner'    # Join type ('inner', 'outer', 'left', 'right')\n",
    ")\n",
    "df = pd.concat([df_1, merged_df])\n",
    "new_df = df[['Client_Income', 'Car_Owned', 'Bike_Owned', 'Active_Loan', 'House_Own', 'Credit_Amount', 'Loan_Annuity', 'Client_Income_Type',\n",
    "            'Client_Education', 'Age_Days', 'Employed_Days', 'Registration_Days', 'ID_Days', 'Client_Family_Members', 'Phone_Change', 'Credit_Bureau',\n",
    "            'Default']].copy()\n",
    "\n",
    "cols_to_numeric = ['Client_Income', 'Car_Owned', 'Bike_Owned', 'Active_Loan', 'House_Own', 'Credit_Amount', 'Loan_Annuity',\n",
    "                  'Age_Days', 'Employed_Days', 'Registration_Days', 'ID_Days', 'Client_Family_Members', 'Phone_Change', 'Credit_Bureau']\n",
    "\n",
    "new_df[cols_to_numeric] = new_df[cols_to_numeric].apply(pd.to_numeric, errors='coerce')\n",
    "new_df = new_df.dropna(axis=0)\n",
    "new_df = new_df[['Client_Income', 'Credit_Amount', 'Loan_Annuity', 'Age_Days', 'Employed_Days', 'Registration_Days', 'ID_Days', \n",
    "                 'Phone_Change', 'Credit_Bureau', 'Client_Education', 'Default']]\n",
    "\n",
    "new_df['Client_Education'] = new_df['Client_Education'].str.lower()  # Lowercase all\n",
    "new_df['Client_Education'] = new_df['Client_Education'].str.replace(' ', '_')  # Standardize\n",
    "\n",
    "education_to_days = {\n",
    "    'junior_secondary': 3285,\n",
    "    'secondary': 4380,\n",
    "    'graduation_dropout': 5110,\n",
    "    'graduation': 5840,\n",
    "    'post_grad': 6570\n",
    "}\n",
    "\n",
    "new_df['Education_Days'] = new_df['Client_Education'].map(education_to_days)\n",
    "new_df = new_df.drop(columns=['Client_Education'])\n",
    "\n",
    "# Reducing age on 10 years if a person is older than 30\n",
    "new_df['Age_Days'] = new_df['Age_Days'].apply(lambda x: x - 3650 if x > 11000 else x)\n",
    "new_df.rename(columns={'Default': 'Divorce'}, inplace=True)\n",
    "\n",
    "# Adding dates for 2023-2024 (106990 rows)\n",
    "date_rng = pd.date_range(start='2023-05-01', end='2024-12-31', freq='D')\n",
    "dates = np.repeat(date_rng, 179)  # 179 rows per date\n",
    "dates = dates[:106990]  # Cut off 106990 rows\n",
    "\n",
    "# Updating new_df index\n",
    "new_df.reset_index(inplace=True, drop=True)\n",
    "new_df = new_df.astype('int32')\n",
    "new_df['Date'] = dates\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "544b9d0c-cb37-4cc3-9bb4-e222a993b479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total obs: 213,990\n",
      "\n",
      "Obs num over years:\n",
      "Date\n",
      "2023    43855\n",
      "2024    63135\n",
      "2025    80618\n",
      "2026    26382\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Divorce rate by year:\n",
      "Date\n",
      "2023    0.079102\n",
      "2024    0.026610\n",
      "2025    0.134263\n",
      "2026    0.129369\n",
      "Name: Divorce, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "''' Adding new year of mock data with drift '''\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Adding new mock year data\n",
    "# 1. 87k random rows from 2023-2024\n",
    "sample_87k = np.random.choice(new_df.index, 87000, replace=True)\n",
    "df_87k = new_df.loc[sample_87k].copy()\n",
    "\n",
    "\n",
    "# 2. 20k new wave young people (age < 27y) with much 50% divorce rate\n",
    "youth_mask = new_df['Age_Days'] < 9855\n",
    "df_youth = new_df[youth_mask].sample(20000, replace=True)\n",
    "df_youth['Divorce'] = np.random.binomial(1, 0.5, 20000)\n",
    "\n",
    "# Adding dates to 2025-2026 dataset\n",
    "date_rng_2025 = pd.date_range(start='2025-01-01', end='2026-04-30', freq='D')\n",
    "dates_2025 = np.random.choice(date_rng_2025, 107000)\n",
    "\n",
    "# Creating date colums\n",
    "df_87k['Date'] = dates_2025[:87000]  # First 87K rows normal\n",
    "df_youth['Date'] = dates_2025[87000:]  # Last 20K rows of youth\n",
    "\n",
    "final_df = pd.concat([new_df, df_87k, df_youth]).sort_values(by='Date', ascending=True)\n",
    "final_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# 5. Checking the result\n",
    "print(f\"Total obs: {len(final_df):,}\")\n",
    "print(\"\\nObs num over years:\")\n",
    "print(final_df['Date'].dt.year.value_counts().sort_index())\n",
    "print(\"\\nDivorce rate by year:\")\n",
    "print(final_df['Divorce'].groupby(final_df['Date'].dt.year).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2aab3d6-f616-48b3-954e-b3437a6d5fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is saved to request_drift.json\n"
     ]
    }
   ],
   "source": [
    "''' Creating request_drift.json for testing drift monitor '''\n",
    "\n",
    "import json\n",
    "\n",
    "target_date = '2025-06-01'\n",
    "sample_df = final_df[final_df['Date'] > target_date].head(1001)\n",
    "sample_df.drop(columns = ['Date', 'Divorce'], inplace=True)\n",
    "\n",
    "result = {\n",
    "    \"instances\": sample_df.to_dict('records')\n",
    "}\n",
    "with open('request_drift.json', 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "\n",
    "print(\"Data is saved to request_drift.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ce50e6-1d77-4dab-8abc-d52779f16676",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creating PostrgeSQL database from final_df '''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, Date\n",
    "import psycopg2\n",
    "from sqlalchemy.exc import OperationalError\n",
    "import time\n",
    "\n",
    "# 1. Connection config\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"localhost\", \n",
    "    \"port\": 5432,\n",
    "    \"user\": \"myuser\",\n",
    "    \"password\": \"mypassword\",\n",
    "    \"database\": \"mydatabase\"\n",
    "}\n",
    "\n",
    "# 2. Checking connection func\n",
    "def connect_to_postgres():\n",
    "    max_retries = 5\n",
    "    db_url = f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "    \n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            engine = create_engine(db_url)\n",
    "            with engine.connect() as conn:\n",
    "                print(\"✅ Successfully connected to PostgreSQL!\")\n",
    "                return engine\n",
    "        except OperationalError as e:\n",
    "            if i == max_retries - 1:\n",
    "                print(\"❌ Could not connect to PostgreSQL.\")\n",
    "                raise\n",
    "            print(f\"⚠️ Trial {i+1}/{max_retries}: Waiting to connect...\")\n",
    "            time.sleep(5)\n",
    "\n",
    "# 3. Load dataframe to PostgreSQL func\n",
    "def load_dataframe_to_postgres(df, table_name, engine):\n",
    "    try:\n",
    "        df.to_sql(\n",
    "            name=table_name,\n",
    "            con=engine,\n",
    "            if_exists='replace',\n",
    "            index=True,\n",
    "            method='multi',\n",
    "            chunksize=10000,\n",
    "            dtype={'Date': Date()}\n",
    "        )\n",
    "        print(f\"✅ Data is successefully loaded to the table '{table_name}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error of loading the data: {e}\")\n",
    "        raise\n",
    "\n",
    "# 4. Checking the data: divorce dare by years\n",
    "def analyze_divorce_rate(conn):\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        EXTRACT(YEAR FROM \"Date\") AS year,\n",
    "        ROUND(AVG(\"Divorce\")::numeric, 6) AS divorce_rate,\n",
    "        COUNT(*) AS observations_count\n",
    "    FROM divorce_predictions\n",
    "    GROUP BY year\n",
    "    ORDER BY year;\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query, conn)\n",
    "\n",
    "# ======================\n",
    "# Main process\n",
    "# ======================\n",
    "\n",
    "# Connecting к PostgreSQL\n",
    "print(\"\\n🔗 Connecting к PostgreSQL...\")\n",
    "engine = connect_to_postgres()\n",
    "\n",
    "# Loading the data\n",
    "print(\"\\n📤 Loading the data to PostgreSQL...\")\n",
    "load_dataframe_to_postgres(final_df, 'divorce_predictions', engine)\n",
    "\n",
    "# Checking data\n",
    "print(\"\\n📊 Checking data...\")\n",
    "with engine.connect() as conn:\n",
    "    result = analyze_divorce_rate(conn)\n",
    "    print(\"\\nDivorce rate by years:\")\n",
    "    display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e299b3-ca76-4f84-b4e9-b0867d817af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create dump of PostgreSQL volume to sql file  \"\"\"\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "postgres_bin = r\"C:\\Program Files\\PostgreSQL\\13\\bin\"\n",
    "os.environ['PATH'] += os.pathsep + postgres_bin\n",
    "\n",
    "def create_pg_dump(db_config, output_file=None):\n",
    "    if not output_file:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%S\")\n",
    "        output_file = f\"Divorce_database_{timestamp}.sql\"\n",
    "    \n",
    "    try:\n",
    "        # Setting env variables for pg_dump\n",
    "        env = os.environ.copy()\n",
    "        env['PGPASSWORD'] = db_config['password']\n",
    "        \n",
    "        # Creating command pg_dump\n",
    "        cmd = [\n",
    "            'pg_dump',\n",
    "            '-h', db_config['host'],\n",
    "            '-p', str(db_config['port']),\n",
    "            '-U', db_config['user'],\n",
    "            '-d', db_config['database'],\n",
    "            '-f', output_file,\n",
    "            '--clean',        \n",
    "            '--if-exists',    \n",
    "            '--no-owner',     \n",
    "            '--format=p',     \n",
    "            '--encoding=UTF8' \n",
    "        ]\n",
    "        \n",
    "        # Running the command\n",
    "        subprocess.run(cmd, env=env, check=True)\n",
    "        print(f\"✅ Dump is created: {output_file}\")\n",
    "        return output_file\n",
    "    \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Error of dump creation: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run dump creation with DB_CONFIG\n",
    "create_pg_dump(DB_CONFIG)\n",
    "\n",
    "# Close connection to DB\n",
    "engine.dispose()\n",
    "print(\"\\n✅ Connection to DB is closed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud",
   "language": "python",
   "name": "fraud"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
